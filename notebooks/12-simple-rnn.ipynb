{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: RNN's\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesse exemplo usar RNN's básicas para classificar de sequências simuladas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos gerar sequências de números aleatórios que podem ser crescentes ou decrescentes:\n",
        "\n",
        "1. Definimos se a sequência vai ser crescente ou decrescente,\n",
        "2. Para cada sequencia, geramos `l` números aleatórios. \n",
        "3. Se a sequência for crescente, ordenamos os números de forma crescente, se não for, ordenamos de forma decrescente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 10000\n",
        "l = 10\n",
        "\n",
        "cresc = np.random.randint(0, 2, size=(n,))\n",
        "x = np.empty((n, l), dtype=np.float32)\n",
        "for i, cr in enumerate(cresc):\n",
        "    tmp = np.random.uniform(size=(l,))\n",
        "    if cr == 1:\n",
        "        x[i, :] = tmp[np.argsort(tmp)]\n",
        "    else:\n",
        "        x[i, :] = tmp[np.argsort(-tmp)]\n",
        "x = x.reshape((n, l, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora vamos definir o modelo no Keras. Não vamos nos preocupar com os\n",
        "parâmetros nem nada ainda. A seguir vamos mostrar exatamente as contas que o Keras está fazendo por trás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input = keras.layers.Input(shape=(l, 1))\n",
        "output = keras.layers.SimpleRNN(units=1, activation=\"tanh\", use_bias=False)(input)\n",
        "output = keras.layers.Activation(\"sigmoid\")(output)\n",
        "model = keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora ajustamos o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| layout-ncol: 1\n",
        "#| column: screen-right\n",
        "model.fit(x=x, y=cresc, epochs=10, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vimos que a RNN consegue prever bem se a sequência é crescente ou decrescente.\n",
        "\n",
        "Agora vamos ver exatamente as contas que o Keras faz. \n",
        "Primeiro, definimos a função sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depois, pegamos o valor do peso estimado pelo Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w_rnn = model.layers[1].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos escolher a primeira observação, para mostrar a conta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_ = x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora o loop que acontece dentro da RNN. Começando com um estado inicial `s=0`, fazemos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = 0.0\n",
        "for i in range(l):\n",
        "    s = np.tanh(w_rnn[0] * x_[i] + w_rnn[1] * s)\n",
        "sigmoid(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em cada passo o estado é atualizado com um peso para o estado anterior e outro para a nova observação, passando por uma função de ativação.\n",
        "Podemos comparar isso com o resultado do Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.predict(x)[0]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}