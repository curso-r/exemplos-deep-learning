{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Regressão Linear\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O objetivo desse exemplo é simular alguns dados e ajustar um modelo\n",
        "de regressão linear usando o método da descida do gradiente.\n",
        "Importante notar que queremos implementar o método da descida do gradiente de forma manual, isto é, sem usar bibliotecas que calculam \n",
        "a derivada automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em primeiro lugar simulamos alguns dados. `x` vai ser uma variável contendo `n` valores aleatórios obtidos a partir da distribuição uniforme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 1000\n",
        "x = np.random.uniform(size=(n,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em seguida definimos os pesos `W` e `b` para a simulação. Nosso objetivo depois, vai ser *fingir* que não sabemos esses valores e ajustar um modelo para encontrá-los."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "W = 0.9\n",
        "b = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos então a variável resposta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = W * x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora vamos definir o nosso modelo. Ele é uma classe do python que recebe os valores iniciais dos pesos `w` e `b` na inicialização e possui o método `predict` que\n",
        "faz uma transformação linear `w*x + b` no input `x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Model:\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.w * x + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora vamos definir a função de perda. Nesse caso estamos usando o erro quadrático médio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def loss(y_true, y_hat):\n",
        "    return np.mean((y_true - y_hat) ** 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Também definimos as derivadas da função de perda `l` em relação a cada uma das partes do grafo de computação até chegar nos parâmetros que queremos estimar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# derivada da função de perda em relação à y_hat\n",
        "def dl_dyhat(y_hat, x, y):\n",
        "    return 2 * (y - y_hat) * (-1)\n",
        "\n",
        "# derivada de y_hat com relação a w\n",
        "def dyhat_dw(y_hat, x, y):\n",
        "    return x\n",
        "\n",
        "# derivada de y_hat com relação a b (viés)\n",
        "def dyhat_db(y_hat, x, y):\n",
        "    return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora vamos inicializar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w = np.random.uniform(size=1)\n",
        "b = 0.0\n",
        "model = Model(w, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E podemos, finalmente, implementar o método da descida do gradiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lr = 0.1 # learning rate - qual o tamanho do passo que damos em cada iteração.\n",
        "for step in range(500):\n",
        "    y_hat = model.predict(x)\n",
        "    dldyhat = dl_dyhat(y_hat, x, y)\n",
        "    model.w -= lr * np.mean(dldyhat * dyhat_dw(y_hat, x, y))\n",
        "    model.b -= lr * np.mean(dldyhat * dyhat_db(y_hat, x, y))\n",
        "    if (step % 100) == 0:\n",
        "        print(\"step:\", step, \"loss:\", loss(y, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verificamos que o resultado está conforme o esperado. Isto é, `w` e `b` estão\n",
        "parecidos com os valores usamos para gerar os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.w)\n",
        "print(model.b)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}