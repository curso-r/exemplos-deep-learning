{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Modelo pré-treinado\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesse exemplo vamos ajustar um modelo pré-treinado para a mesma base usando embeddings provenientes de um tipo de modelo que é bem avançado chamado BERT.\n",
        "Para isso vamos usar o tfhub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_text\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A tarefa será bem similar com o que fizemos quando usamos modelos pré treinados\n",
        "para imagens.\n",
        "\n",
        "Em primeiro lugar vamos obter o banco de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/deep-learning-com-r/toxic-comments.csv\"\n",
        ")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Os modelos pré-treinados do tfhub já incluem as suas camadas de pré-processamento, portanto não precisamos nos preocupar em pré-processar\n",
        "os textos usando a camada de vetorização. Eles também incluem os embeddings, portanto não vamos criar essas camadas. Muitos dos modelos também retornam embeddings completas para os textos, não apenas para as palavras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = dataset[\"comment_text\"].to_numpy()\n",
        "y = dataset.iloc[:, 2:].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos definir o modelo no Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "input = keras.layers.Input(shape=(), dtype=\"string\")\n",
        "encoded = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")(\n",
        "    input\n",
        ")\n",
        "encoded = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\", trainable=False\n",
        ")(encoded)\n",
        "\n",
        "output = keras.layers.Dense(units=y.shape[1], activation=\"sigmoid\")(encoded[\"default\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O modelo pode ser definido com:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "model = keras.Model(inputs=input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora podemos ajustar o modelo. Basicamente só estamos ajustando classificador que se baseia nas embeddings criadas pelo BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| layout-ncol: 1\n",
        "#| column: screen-right\n",
        "#| eval: false\n",
        "auc = keras.metrics.AUC(curve=\"ROC\")\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\", auc])\n",
        "\n",
        "model.fit(x, y, epochs=1, batch_size=32, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "#| layout-ncol: 1\n",
        "#| column: screen-right\n",
        "3990/3990 [==============================] - 1181s 295ms/step - loss: 0.1078 - accuracy: 0.9733 - auc: 0.8957 - val_loss: 0.0969 - val_accuracy: 0.9146 - val_auc: 0.9244\n",
        "```\n",
        "\n",
        "O modelo demora para rodar. Mas em apenas uma época conseguimos um bom resultado.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}