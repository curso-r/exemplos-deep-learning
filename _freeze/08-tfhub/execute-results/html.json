{
  "hash": "a8d514a6206973688f0f974afe28ff6b",
  "result": {
    "markdown": "---\ntitle: Modelos pré-treinados\n---\n\nNeste exemplo, ao invés de treinarmos um modelo convolucional do zero, como fizemos\nno [exemplo 07](./07-conv-mnist.html), vamos usar um modelo pré treinado. Para isso\nusaremos o TensorFlow Hub - bibilioteca que facilita todas as etapas para usar modelos\npré treinados.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom tensorflow import keras\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nA base de dados que vamos usar será o CIFAR10 que pode ser carregada no Keras com:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n```\n:::\n\n\nPodemos visualizar algumas imagens:\nAgora podemos visualizar algumas imagens do banco de dados:\n\n::: {.cell .column-screen-right layout-ncol='3' execution_count=3}\n``` {.python .cell-code}\nplt.imshow(x_train[0])\nplt.show()\nplt.imshow(x_train[1])\nplt.show()\nplt.imshow(x_train[2])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](08-tfhub_files/figure-html/cell-4-output-1.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](08-tfhub_files/figure-html/cell-4-output-2.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](08-tfhub_files/figure-html/cell-4-output-3.png){width=408 height=404}\n:::\n:::\n\n\nVamos agora definir o modelo. Ponto importantes:\n\n1. Cada modelo no tfhub possui uma documentação ([exemplo](https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/5)) que vai falar o formato esperado da imagem. No caso deste MobileNet que estamos usando é esperado que a imagem tenha cores como valores entre 0 e 1 e que a imagem tenha tamanho 224x224.\n2. Usamos as camadas `Rescaling` e `Resizing` mudar as cores de inteiros de [1,255] em\nvalores entre 0 e 1 e para aumentar o tamanho das imagens de 32x32 para 224x224.\n3. Para usar o modelo pré treinado, basta passar a sua URL para a camada `hub.KerasLayer`. Usamos `trainable=False` pois queremos deixar fixos os pesos deste modelo.\n4. O modelo pré-treinado está transformando cada imagem em um vetor de tamanho 1024. Em seguida usamos uma regressão multinomial p/ classificar nas 10 classes do CIFAR10.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ninput = keras.layers.Input(shape=(32, 32, 3))\nout = keras.layers.Rescaling(1 / 255.0)(input)\nout = keras.layers.Resizing(224, 224)(out)\nout = hub.KerasLayer(\n    handle=\"https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/5\",\n    trainable=False,\n)(out)\nout = keras.layers.Dropout(rate=0.2)(out)\nout = keras.layers.Dense(units=10, activation=\"softmax\")(out)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2022-04-28 10:23:31.586158: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n```\n:::\n:::\n\n\nVeja que a camada do TFHUB possui todos os pesos do MobileNet.\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=5}\n``` {.python .cell-code}\nmodel = keras.Model(inputs=input, outputs=out)\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"model\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n rescaling (Rescaling)       (None, 32, 32, 3)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n resizing (Resizing)         (None, 224, 224, 3)       0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n keras_layer (KerasLayer)    (None, 1024)              3228864   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout (Dropout)           (None, 1024)              0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense (Dense)               (None, 10)                10250     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 3,239,114\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 10,250\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 3,228,864\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\nAgora podemos compilar o modelo:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nmodel.compile(\n    optimizer=\"adam\",\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n```\n:::\n\n\nEstamos usando a mesma loss que usamos no [exemplo anterior](./07-conv-mnist.html).\nAgora vamos ajustar o modelo. É esperado termos um acerto bem maior do que se tivéssemos ajustado um modelo do zero, pois o modelo pré treinado foi ajustado\nem banco de dados muito maiores e por isso tem bastante informação p/ agregar.\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=7}\n``` {.python .cell-code}\nhist = model.fit(x_train, y_train, epochs=5, validation_split=0.2, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1250/1250 - 1259s - loss: 0.6180 - accuracy: 0.7867 - val_loss: 0.3967 - val_accuracy: 0.8616 - 1259s/epoch - 1s/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 2/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1250/1250 - 1133s - loss: 0.4270 - accuracy: 0.8516 - val_loss: 0.3835 - val_accuracy: 0.8634 - 1133s/epoch - 907ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 3/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1250/1250 - 1250s - loss: 0.4012 - accuracy: 0.8590 - val_loss: 0.3635 - val_accuracy: 0.8702 - 1250s/epoch - 1000ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 4/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1250/1250 - 1218s - loss: 0.3934 - accuracy: 0.8648 - val_loss: 0.3588 - val_accuracy: 0.8717 - 1218s/epoch - 974ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 5/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1250/1250 - 1204s - loss: 0.3822 - accuracy: 0.8676 - val_loss: 0.3640 - val_accuracy: 0.8719 - 1204s/epoch - 963ms/step\n```\n:::\n:::\n\n\n",
    "supporting": [
      "08-tfhub_files"
    ],
    "filters": [],
    "includes": {}
  }
}