{
  "hash": "8f4c11023d62cf844bbce57a890aa977",
  "result": {
    "markdown": "---\ntitle: MNIST\n---\n\nFalamos um pouco do MNIST no [exemplo 6](./06-convolution.html) e neste exemplo\nvamos ajustar uma rede neural convolucional para prever os dígitios do MNIST.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nO banco de dados do MNIST pode ser obtido usando funções prontas do Keras.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n```\n:::\n\n\nAgora podemos visualizar algumas imagens do banco de dados:\n\n::: {.cell .column-screen-right layout-ncol='3' execution_count=3}\n``` {.python .cell-code}\nplt.imshow(x_train[0])\nplt.show()\nplt.imshow(x_train[1])\nplt.show()\nplt.imshow(x_train[2])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](07-conv-mnist_files/figure-html/cell-4-output-1.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](07-conv-mnist_files/figure-html/cell-4-output-2.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](07-conv-mnist_files/figure-html/cell-4-output-3.png){width=408 height=404}\n:::\n:::\n\n\nOs vetores `y_train` e `y_test` possuem o valor representado pelo dígito que\nestá na imagem.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nprint(y_train[0:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[5 0 4]\n```\n:::\n:::\n\n\nNote que as imagens do MNIST são tamanho 28x28x1 (o 1 vem do núemro de canais - como a \nimagem é P&B só temos 1 canal.)\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nx_train.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(60000, 28, 28)\n```\n:::\n:::\n\n\nAgora vamos definir o modelo. Ponto importantes:\n\n1. O input do modelo tem formato 28x28x1. Isso é a altura e largura das imagens\ndo input é 28 e a imagem é P&B, 1 canal.\n2. As imagens estão representadas por número inteiros de 0 a 255, é importante\nfazer o *rescaling*  e transformar esses valores em números entre 0 e 1, para não\ntermos problemas com o algoritmo de otimização.\n3. Estamos usando 4 blocos de convolução/ pooling. Em cada um deles aumentamos o\nnúmero de filtros da convolução e o 'pooling' será reponsável por diminuir o\ntamanho da imagem.\n4. O `Flatten` tira as dimensões que não estão sendo usadas e transforma o output\nem um **vetor**.\n5. No final colocamos um MLP. Note que o número de outputs da última camada é 10,\npois temos 10 classes possíveis (dígitos de 0 a 9). A ativação é softmax pois \ncada imagem pertence a uma única classe. Portanto as probabilidades por linha devem\nsomar 1.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ninput = keras.layers.Input(shape=(28, 28, 1))\noutput = keras.layers.Rescaling(1.0/255.0)(input)\n\noutput = keras.layers.Conv2D(\n    kernel_size=(3, 3), filters=32, activation=\"relu\", padding=\"same\"\n)(output)\noutput = keras.layers.MaxPool2D(pool_size=(2, 2))(output)\n\noutput = keras.layers.Conv2D(\n    kernel_size=(3, 3), filters=64, activation=\"relu\", padding=\"same\"\n)(output)\noutput = keras.layers.MaxPool2D(pool_size=(2, 2))(output)\n\noutput = keras.layers.Conv2D(\n    kernel_size=(3, 3), filters=128, activation=\"relu\", padding=\"same\"\n)(output)\noutput = keras.layers.MaxPool2D(pool_size=(2, 2))(output)\n\noutput = keras.layers.Conv2D(\n    kernel_size=(3, 3), filters=256, activation=\"relu\", padding=\"same\"\n)(output)\noutput = keras.layers.MaxPool2D(pool_size=(2, 2))(output)\n\noutput = keras.layers.Flatten()(output)\noutput = keras.layers.Dense(128, activation=\"relu\")(output)\noutput = keras.layers.Dense(10, activation=\"softmax\")(output)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2022-04-27 22:22:08.279452: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n```\n:::\n:::\n\n\nAgora criamos o modelo do Keras\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=7}\n``` {.python .cell-code}\nmodel = keras.Model(inputs=input, outputs=output)\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"model\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n rescaling (Rescaling)       (None, 28, 28, 1)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d (Conv2D)             (None, 28, 28, 32)        320       \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n )                                                               \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n 2D)                                                             \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n 2D)                                                             \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_3 (Conv2D)           (None, 3, 3, 256)         295168    \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n 2D)                                                             \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n flatten (Flatten)           (None, 256)               0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense (Dense)               (None, 128)               32896     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_1 (Dense)             (None, 10)                1290      \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 422,026\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 422,026\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 0\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\nVeja o número de parâmetros da primeira camada de convolução. Você pode pensar da seguinte forma:\n\n1. Cada kernel tem 3x3 parâmetros.\n2. Cada filtro tem 1 kernel.\n3. Cada filtro possui um viés.\n4. Total: 3x3x32 + 32\n\nPara a segunda camada a conta é a mesma, mas o input agora não possui apenas um canal. \nAgora o input possui 32 canais então pensamos:\n\n1. Cada kernel tem 3x3x32 parâmetros.\n2. Cada filtro tem 1 kernel.\n3. Cada filtro possui um viés.\n4. Total: 3x3x32x64 + 64\n\nAgora podemos compilar o modelo.\nUsamos a 'sparse_categorical_crossentropy' pois o problema de classificação em muitas classes.\nO `sparse` é usado para não precisar transformar o vetor de resposta `y_train` em uma\nmatriz com one-hot encode.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n```\n:::\n\n\nEntão, podemos ajustar o modelo:\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=9}\n``` {.python .cell-code}\nmodel.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2,\n          verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1500/1500 - 62s - loss: 0.8062 - accuracy: 0.7558 - val_loss: 0.1782 - val_accuracy: 0.9439 - 62s/epoch - 41ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 2/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1500/1500 - 53s - loss: 0.1357 - accuracy: 0.9585 - val_loss: 0.0961 - val_accuracy: 0.9704 - 53s/epoch - 35ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 3/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1500/1500 - 56s - loss: 0.0929 - accuracy: 0.9711 - val_loss: 0.0938 - val_accuracy: 0.9715 - 56s/epoch - 37ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 4/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1500/1500 - 53s - loss: 0.0712 - accuracy: 0.9773 - val_loss: 0.0754 - val_accuracy: 0.9763 - 53s/epoch - 35ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 5/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1500/1500 - 51s - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.0613 - val_accuracy: 0.9815 - 51s/epoch - 34ms/step\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n<keras.callbacks.History at 0x7fae30c74e80>\n```\n:::\n:::\n\n\nVamos também verificar a matriz de confusão para a base de teste. Note que para \nencontrar a classe predita, pegamos a classe com maior probabilidade.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nmetrics.confusion_matrix(\n    y_test, np.argmax(model.predict(x_test), axis=1)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([[ 965,    0,    1,    0,    2,    1,    1,    3,    3,    4],\n       [   0, 1126,    2,    0,    1,    1,    2,    2,    1,    0],\n       [   0,    0, 1024,    2,    0,    0,    0,    6,    0,    0],\n       [   0,    0,    0,  998,    0,    5,    0,    3,    3,    1],\n       [   0,    0,    1,    0,  979,    0,    1,    0,    0,    1],\n       [   1,    0,    0,    4,    1,  879,    2,    2,    0,    3],\n       [   2,    2,    1,    0,    7,    8,  937,    0,    1,    0],\n       [   0,    2,    6,    1,    1,    0,    0, 1013,    1,    4],\n       [   2,    0,    5,    8,    5,    5,    0,    6,  933,   10],\n       [   0,    3,    0,    2,   11,    1,    0,    4,    2,  986]])\n```\n:::\n:::\n\n\n",
    "supporting": [
      "07-conv-mnist_files"
    ],
    "filters": [],
    "includes": {}
  }
}