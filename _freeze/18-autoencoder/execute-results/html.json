{
  "hash": "76a581263d53b2cb07d1198b70468287",
  "result": {
    "markdown": "---\ntitle: Autoencoder\n---\n\nNesse exemplo vamos ajustar um autoencoder com autoencoder na base do MNIST.\nVamos também mostrar alguns dos possíveis usos do Autoencoder.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nVamos obter o banco de dados:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n```\n:::\n\n\nPodemos visualizar algumas imagens com:\n\n::: {.cell .column-screen-right layout-ncol='3' execution_count=3}\n``` {.python .cell-code}\nplt.imshow(x_train[0])\nplt.show()\nplt.imshow(x_train[1])\nplt.show()\nplt.imshow(x_train[2])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](18-autoencoder_files/figure-html/cell-4-output-1.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](18-autoencoder_files/figure-html/cell-4-output-2.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](18-autoencoder_files/figure-html/cell-4-output-3.png){width=408 height=404}\n:::\n:::\n\n\nAgora vamos definir o modelo. Nesse exemplo vamos usar uma forma um pouco diferente\nde definir o modelo que é usando classes. Dessa forma, podemos encapsular um pouco\nmelhor o código. Também usaremos a `keras.Sequential` pela primeira vez, por isso\nvamos entender o que ele faz.\n\nOs 3 modelos definidos a seguir são equivalentes:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Usando a API funcional\ninput = keras.layers.Input(shape=(28,28,1))\noutput = keras.layers.Flatten()(input)\noutput = keras.layers.Dense(units=64, activation=\"relu\")(output)\nmodel = keras.Model(inputs=input, outputs=output)\n\n# Usando a API sequencial\nmodel = keras.Sequential([\n  keras.layers.Flatten(),\n  keras.layers.Dense(units=64, activation='relu'),\n])\n\n# usando a API de classes\nclass Modelo(keras.Model):\n  def __init__(self):\n    super(Modelo, self).__init__()\n    self.flatten = keras.layers.Flatten()\n    self.dense = keras.layers.Dense(units=64, activation=\"relu\")\n  def call(self, x):\n    out = self.flattent(x)\n    return self.dense(out)\n```\n:::\n\n\nA vantagem da API sequencial do Keras é ser menos verbosa. No entanto, didaticamente\na API funcional é mais clara, pois ela nos força a pensar em qual é o nosso input\ne como as camadas são combinadas. Já a API de classes é útil para modelos mais\ncomplicados pois permite que possamos encapsular melhor os códigos.\n**Note** que podemos misturar todas as API's no mesmo código e isso é considerado idiomático.\n\n\nAgora vamos definir o autoencoder. Definimos ele em duas partes:\n\n- Um encoder, que transforma a imagem do MNIST em um vetor.\n- Um decoder, que pega um vetor e transforma de volta em uma imagem.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nclass Autoencoder(keras.Model):\n  def __init__(self, latent_dim):\n    super(Autoencoder, self).__init__()\n    self.latent_dim = latent_dim   \n    self.encoder = keras.Sequential([\n      keras.layers.Rescaling(scale=1./255),\n      keras.layers.Flatten(),\n      keras.layers.Dense(latent_dim, activation='relu'),\n    ])\n    self.decoder = keras.Sequential([\n      keras.layers.Dense(784, activation='sigmoid'),\n      keras.layers.Reshape((28, 28, 1)),\n      keras.layers.Rescaling(scale=255.)\n    ])\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded\n```\n:::\n\n\nPara incializar um modelo definido como uma classe usamos:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nautoencoder = Autoencoder(latent_dim=64)\n```\n:::\n\n\nEntão podemos compilar:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nautoencoder.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n```\n:::\n\n\nE ajustar:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nautoencoder.fit(x_train, x_train,\n  epochs=10,\n  shuffle=True,\n  validation_data=(x_test, x_test),\n  verbose=2\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 1555.8877 - val_loss: 605.1500 - 2s/epoch - 1ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 2/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 452.4213 - val_loss: 349.3282 - 2s/epoch - 948us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 3/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 329.5283 - val_loss: 296.8387 - 2s/epoch - 969us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 4/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 298.9903 - val_loss: 277.7961 - 2s/epoch - 958us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 5/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 286.0212 - val_loss: 278.3241 - 2s/epoch - 943us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 6/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 278.3516 - val_loss: 268.9713 - 2s/epoch - 932us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 7/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 271.6905 - val_loss: 264.3178 - 2s/epoch - 924us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 8/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 266.9784 - val_loss: 256.6068 - 2s/epoch - 962us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 9/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 262.8771 - val_loss: 257.2297 - 2s/epoch - 1ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 10/10\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n1875/1875 - 2s - loss: 259.5267 - val_loss: 254.3345 - 2s/epoch - 1ms/step\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n<keras.callbacks.History at 0x7fe645536e50>\n```\n:::\n:::\n\n\nPodemos usar o autoencoder para simplificar e depois reconstruir uma imagem:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nencoded = autoencoder.encoder.predict(x_test)\ndecoded = autoencoder.decoder.predict(encoded)\n```\n:::\n\n\nO 'encoder' do nosso autoencoder representa cada imagem como um vetor e esse vetor\npode ser usado para comparar imagens, ou para ser input de algum outro modelo.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nencoded[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\narray([ 2.7154648,  3.3469846,  5.0955553,  4.928041 ,  1.4984177,\n        3.5500624,  6.6044536,  4.8169136,  1.8987292,  3.7721162,\n        0.       , 10.673604 ,  3.438078 ,  4.828475 ,  3.6719105,\n        3.3354235,  3.8524048,  6.96551  ,  5.3519597,  6.073485 ,\n        1.730966 ,  3.6241064,  4.7289557,  5.14427  ,  5.7000866,\n        7.9746943,  4.687333 ,  3.6276262,  4.513113 ,  2.5262182,\n        2.7582881,  4.5068583,  5.326924 ,  1.5850337,  2.8732448,\n        2.304493 ,  5.060994 ,  5.387458 ,  0.7613592,  1.4485734,\n        0.       ,  2.7385345,  3.6030219, 13.330053 ,  2.6578474,\n        4.0867414,  4.838855 ,  4.833501 ,  3.9582207,  0.       ,\n        3.4030182,  2.8294477,  5.486768 ,  1.9036677,  3.8831449,\n        3.3715608,  3.5314097,  1.7339928,  3.1415982,  5.773363 ,\n        5.608508 ,  1.4208441,  4.4426064,  2.196546 ], dtype=float32)\n```\n:::\n:::\n\n\nVisualize a imagem antes e depois:\n\n::: {.cell .column-screen-right layout-ncol='2' execution_count=11}\n``` {.python .cell-code}\nplt.imshow(x_test[0])\nplt.show()\nplt.imshow(decoded[0].astype(\"uint8\"))\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](18-autoencoder_files/figure-html/cell-12-output-1.png){width=408 height=404}\n:::\n\n::: {.cell-output .cell-output-display}\n![](18-autoencoder_files/figure-html/cell-12-output-2.png){width=408 height=404}\n:::\n:::\n\n\n",
    "supporting": [
      "18-autoencoder_files"
    ],
    "filters": [],
    "includes": {}
  }
}