{
  "hash": "6d5d1f7aa981f0cf668c1fbbed56d941",
  "result": {
    "markdown": "---\ntitle: Enem\nexecute:\n  eval: false\n---\n\nNesse exemplo vamos fazer um modelo para classificar as perguntas do ENEM eu seus respectivos temas.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom tensorflow import keras\n```\n:::\n\n\nCarregando os dados:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv(\"https://storage.googleapis.com/deep-learning-com-r/banco_de_questoes.csv\",encoding = 'latin2', sep = \";\")\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enunciados</th>\n      <th>url</th>\n      <th>grande_tema</th>\n      <th>subtema</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Uma pessoa precisa comprar 15 sacos de cimento...</td>\n      <td>https://www.projetoagathaedu.com.br/questoes-e...</td>\n      <td>matematica</td>\n      <td>aritmetica-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Antônio, Joaquim e José săo sócios de uma empr...</td>\n      <td>https://www.projetoagathaedu.com.br/questoes-e...</td>\n      <td>matematica</td>\n      <td>aritmetica-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>De acordo com pesquisas recentes, a expectativ...</td>\n      <td>https://www.projetoagathaedu.com.br/questoes-e...</td>\n      <td>matematica</td>\n      <td>aritmetica-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Um jogo pedagógico é formado por cartas nas qu...</td>\n      <td>https://www.projetoagathaedu.com.br/questoes-e...</td>\n      <td>matematica</td>\n      <td>aritmetica-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Em um país, as infraçőes de trânsito săo class...</td>\n      <td>https://www.projetoagathaedu.com.br/questoes-e...</td>\n      <td>matematica</td>\n      <td>aritmetica-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17338</th>\n      <td>Ao final do texto, a autora expőe um posiciona...</td>\n      <td>https://www.projetoagathaedu.com.br/prova-comp...</td>\n      <td>uerj</td>\n      <td>linguagens-2021</td>\n    </tr>\n    <tr>\n      <th>17339</th>\n      <td>As questőes 08 a 11 referem-se ao romance Tri...</td>\n      <td>https://www.projetoagathaedu.com.br/prova-comp...</td>\n      <td>uerj</td>\n      <td>linguagens-2021</td>\n    </tr>\n    <tr>\n      <th>17340</th>\n      <td>5. As questőes 08 a 11 referem-se ao romance ...</td>\n      <td>https://www.projetoagathaedu.com.br/prova-comp...</td>\n      <td>uerj</td>\n      <td>linguagens-2021</td>\n    </tr>\n    <tr>\n      <th>17341</th>\n      <td>As questőes 08 a 11 referem-se ao romance Tri...</td>\n      <td>https://www.projetoagathaedu.com.br/prova-comp...</td>\n      <td>uerj</td>\n      <td>linguagens-2021</td>\n    </tr>\n    <tr>\n      <th>17342</th>\n      <td>As questőes 08 a 11 referem-se ao romance Tri...</td>\n      <td>https://www.projetoagathaedu.com.br/prova-comp...</td>\n      <td>uerj</td>\n      <td>linguagens-2021</td>\n    </tr>\n  </tbody>\n</table>\n<p>17343 rows × 4 columns</p>\n</div>\n```\n:::\n:::\n\n\nVamos separar a resposta e dados de treino\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf.grande_tema.value_counts()\ny = df.grande_tema.astype('category').cat.codes.astype(\"int32\").to_numpy()\nx = df.enunciados.astype(\"str\").to_numpy()\n```\n:::\n\n\nAgora vamos criar a camada de vetorização:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nvectorize = keras.layers.TextVectorization(\n  max_tokens = 10000,\n  pad_to_max_tokens=True\n)\nvectorize.adapt(x)\nvocab = vectorize.get_vocabulary()\n```\n:::\n\n\nEntão podemos definir o modelo\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ninput = keras.layers.Input(shape=(), dtype=\"string\")\noutput = vectorize(input)\noutput = keras.layers.Embedding(input_dim=len(vocab), output_dim=256)(output)\noutput = keras.layers.LSTM(units=256)(output)\noutput = keras.layers.Dense(units=256, activation=\"relu\")(output)\noutput = keras.layers.Dense(units=y.max() + 1, activation=\"softmax\")(output)\n```\n:::\n\n\nCompilar e ajustar\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nmodel = keras.Model(inputs=input, outputs=output)\nauc = keras.metrics.AUC(curve=\"ROC\")\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[auc, \"accuracy\"])\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"model_1\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n input_2 (InputLayer)        [(None,)]                 0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n text_vectorization_1 (TextV  (None, None)             0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n ectorization)                                                   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n embedding_1 (Embedding)     (None, None, 256)         2560000   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n lstm_1 (LSTM)               (None, 256)               525312    \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_2 (Dense)             (None, 256)               65792     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_3 (Dense)             (None, 116)               29812     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 3,180,916\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 3,180,916\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 0\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=7}\n``` {.python .cell-code}\nmodel.fit(\n  x=x, \n  y=keras.utils.to_categorical(y),\n  epochs = 1,\n  verbose = 2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n542/542 - 549s - loss: 4.1006 - auc_1: 0.7647 - accuracy: 0.0834 - 549s/epoch - 1s/step\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n<keras.callbacks.History at 0x7fbb71cf01f0>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "17-enem_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}