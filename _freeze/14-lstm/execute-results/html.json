{
  "hash": "b405b32adcad97e8444b56d16c46c148",
  "result": {
    "markdown": "---\ntitle: Aplicando a LSTM\n---\n\nNesse exemplo vamos aplicar a LSTM ao mesmo banco de dados que fizemos o Pooling. Diferentemente do [exemplo](./11-avg-pooling.qmd) vamos prever para todas as tags do banco de dados. **Note** que são tags, não categorias, cada texto pode ser classificado em mais de uma.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n```\n:::\n\n\nVamos carregar o banco de dados:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndataset = pd.read_csv(\n    \"https://storage.googleapis.com/deep-learning-com-r/toxic-comments.csv\"\n)\ndataset.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNosso objetivo será, a partir do texto do comentário, classificar nas diversas tags possíveis.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nx = dataset['comment_text'].to_numpy()\ny = dataset.iloc[:,2:].to_numpy()\nprint(dataset.columns[2:])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIndex(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate'],\n      dtype='object')\n```\n:::\n:::\n\n\nVamos então criar a camada de vetorização e adaptá-la:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nvectorize = keras.layers.TextVectorization(\n    max_tokens=10000, output_mode=\"int\", output_sequence_length=150\n)\n\nvectorize.adapt(x)\nvocab = vectorize.get_vocabulary()\n```\n:::\n\n\nEm seguida podemos criar o modelo no Keras:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ninput = keras.layers.Input(shape=(), dtype=\"string\")\noutput = vectorize(input)\noutput = keras.layers.Embedding(input_dim=len(vocab), output_dim=2)(output)\noutput = keras.layers.LSTM(units=256)(output)\noutput = keras.layers.Dense(units=y.shape[1], activation=\"sigmoid\")(output)\n\nmodel = keras.Model(inputs=input, outputs=output)\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"model_1\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n input_3 (InputLayer)        [(None,)]                 0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n text_vectorization_2 (TextV  (None, 150)              0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n ectorization)                                                   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n embedding_2 (Embedding)     (None, 150, 2)            20000     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n lstm_2 (LSTM)               (None, 256)               265216    \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_1 (Dense)             (None, 6)                 1542      \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 286,758\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 286,758\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 0\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\nNote que na última camada densa temos `units=y.shape[1]`, isto é, um output para cada tag possível. A ativação é sigmoid, pois queremos prever uma probabilidade para cada coluna.\n\nAgora vamos compilar e ajustar o modelo;\n\n::: {.cell .column-screen-right layout-ncol='1' execution_count=6}\n``` {.python .cell-code}\nauc = keras.metrics.AUC(curve=\"ROC\")\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\", auc])\n\nmodel.fit(x, y, epochs=5, batch_size=32, validation_split=0.2, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3990/3990 - 1162s - loss: 0.1694 - accuracy: 0.9937 - auc_1: 0.7032 - val_loss: 0.1410 - val_accuracy: 0.9941 - val_auc_1: 0.7484 - 1162s/epoch - 291ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 2/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3990/3990 - 12937s - loss: 0.1412 - accuracy: 0.9942 - auc_1: 0.7498 - val_loss: 0.1409 - val_accuracy: 0.9941 - val_auc_1: 0.7484 - 12937s/epoch - 3s/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 3/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3990/3990 - 635s - loss: 0.1412 - accuracy: 0.9942 - auc_1: 0.7494 - val_loss: 0.1410 - val_accuracy: 0.9941 - val_auc_1: 0.7483 - 635s/epoch - 159ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 4/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3990/3990 - 686s - loss: 0.1411 - accuracy: 0.9942 - auc_1: 0.7501 - val_loss: 0.1409 - val_accuracy: 0.9941 - val_auc_1: 0.7472 - 686s/epoch - 172ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 5/5\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3990/3990 - 712s - loss: 0.1411 - accuracy: 0.9942 - auc_1: 0.7495 - val_loss: 0.1409 - val_accuracy: 0.9941 - val_auc_1: 0.7481 - 712s/epoch - 178ms/step\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n<keras.callbacks.History at 0x7fe8a3f70bb0>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "14-lstm_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}